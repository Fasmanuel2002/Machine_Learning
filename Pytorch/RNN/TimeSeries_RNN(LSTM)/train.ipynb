{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49484e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1123c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Period       Revenue  Sales_quantity  Average_cost  \\\n",
      "0  01.01.2015  1.601007e+07         12729.0   1257.763541   \n",
      "1  01.02.2015  1.580759e+07         11636.0   1358.507000   \n",
      "2  01.03.2015  2.204715e+07         15922.0   1384.697024   \n",
      "3  01.04.2015  1.881458e+07         15227.0   1235.606705   \n",
      "4  01.05.2015  1.402148e+07          8620.0   1626.621765   \n",
      "\n",
      "   The_average_annual_payroll_of_the_region  \n",
      "0                                30024676.0  \n",
      "1                                30024676.0  \n",
      "2                                30024676.0  \n",
      "3                                30024676.0  \n",
      "4                                30024676.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Month_value_1.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5378974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of Nans: 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "values = df.iloc[:, 1:5].values\n",
    "features = values.shape[1]\n",
    "total_df_size = df.size\n",
    "values_Nans = df.isna().sum().sum()\n",
    "print(f\"Total of Nans: {values_Nans / total_df_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dcc25bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/64/_d7wbs111535lmdv26qfwp000000gn/T/ipykernel_10438/646466139.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"ffill\", inplace=True)\n",
      "/var/folders/64/_d7wbs111535lmdv26qfwp000000gn/T/ipykernel_10438/646466139.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method=\"bfill\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The total Nans of these DataSet is 26.6%\n",
    "We need to fill it out\n",
    "\"\"\"\n",
    "df.fillna(method=\"ffill\", inplace=True)\n",
    "df.fillna(method=\"bfill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c61b07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of Nans after fillna: 0.0\n"
     ]
    }
   ],
   "source": [
    "values = df.iloc[:, 1:5].values\n",
    "features = values.shape[1]\n",
    "total_df_size = df.size\n",
    "values_Nans = df.isna().sum().sum()\n",
    "print(f\"Total of Nans after fillna: {values_Nans / total_df_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d51c9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "values_evidence_normalize = scaler.fit_transform(values)\n",
    "\n",
    "X, y = [], []\n",
    "#Appending by the window_size that the \n",
    "window_size = 10\n",
    "for i in range(len(values_evidence_normalize) - window_size):\n",
    "    X.append(values_evidence_normalize[i: i + window_size])\n",
    "    y.append(values_evidence_normalize[i + window_size])\n",
    "    \n",
    "X = np.array(X).astype(np.float32)\n",
    "y = np.array(y).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0babbfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (60, 10, 4)\n",
      "Y train shape: (60, 4)\n",
      "X test shape: (26, 10, 4)\n",
      "Y test shape: (26, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.30, shuffle=False\n",
    ")\n",
    "print(f\"X train shape: {X_train.shape}\")\n",
    "print(f\"Y train shape: {Y_train.shape}\")\n",
    "print(f\"X test shape: {X_test.shape}\")\n",
    "print(f\"Y test shape: {Y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d973c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bbad76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, output=features):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        \n",
    "        self.LSTM_1 = nn.LSTM(input_size=X_train.shape[2],\n",
    "                              hidden_size=100, \n",
    "                              num_layers=1,\n",
    "                              batch_first=True)\n",
    "        self.LSTM_2 = nn.LSTM(input_size=100,\n",
    "                            hidden_size=75,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "        self.LSTM_3 = nn.LSTM(input_size=75,\n",
    "                                hidden_size=50,\n",
    "                                num_layers=1,\n",
    "                                batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(50, out_features=output)\n",
    "    def forward(self, x):\n",
    "        for lstm in [self.LSTM_1, self.LSTM_2, self.LSTM_3]:\n",
    "            x, _ = lstm(x)\n",
    "        return self.fc(x[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2fe5182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = LSTM_Model(features)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.AdamW(params=rnn_model.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2a9c6509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/200], Loss: 0.0435\n",
      "Epoch [100/200], Loss: 0.0414\n",
      "Epoch [150/200], Loss: 0.0393\n",
      "Epoch [200/200], Loss: 0.0365\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    rnn_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn_model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    if(epoch +1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3fd945c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Results\n",
      "MSE: 0.0074\n",
      "RMSE: 0.0858\n",
      "MAE: 0.0708\n"
     ]
    }
   ],
   "source": [
    "rnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = rnn_model(x_test).numpy()\n",
    "\n",
    "mse = mean_squared_error(y_test.numpy(), y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test.numpy(), y_pred)\n",
    "\n",
    "print(\"\\n Results\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f5482a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
